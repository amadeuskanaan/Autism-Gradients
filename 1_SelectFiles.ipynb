{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1\n",
    "Selecting subjects based on:\n",
    "- Missing data\n",
    "- SUB_IN_SMP variable (subjects used in the orginal paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import useful things\n",
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# get a list of inputs\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os.path\n",
    "\n",
    "# little helper function to return the proper filelist with the full path but that skips hidden files\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in listdir_nohidden(d)]\n",
    "# and create a filelist\n",
    "onlyfiles = listdir_fullpath(\"./data/Input/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    }
   ],
   "source": [
    "# check to see which files contains nodes with missing information\n",
    "missingarray = []\n",
    "for i in onlyfiles:\n",
    "# load timeseries\n",
    "    filename = i\n",
    "    ts_raw = np.loadtxt(filename)\n",
    "\n",
    "# check zero columns\n",
    "    missingn = np.where(~ts_raw.any(axis=0))[0]\n",
    "    missingarray.append(missingn)\n",
    "\n",
    "# select the ones that don't have missing data\n",
    "ids = np.where([len(i) == 0 for i in missingarray])[0]\n",
    "selected_filename_only = [onlyfiles[i] for i in ids]\n",
    "# could be useful to have one without pathnames later one\n",
    "selected_full_path = [os.path.basename(onlyfiles[i]) for i in ids]\n",
    "print(len(selected_filename_only))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the phenotype file and check to see the filenames match the selected ones and have the SUB_IN_SMP set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read in csv\n",
    "df_phen = pd.read_csv('./data/Phenotypic_V1_0b_preprocessed1_filt.csv')\n",
    "# add a column that matches the filename\n",
    "for i in df_phen:\n",
    "    df_phen['filename_1D'] = join(df_phen['FILE_ID']+\"_rois_cc400.1D\")\n",
    "    df_phen['filename_npy'] = join(df_phen['FILE_ID']+\"_rois_cc400.1D.npy\")\n",
    "\n",
    "df_phen['selected'] = np.where(df_phen['filename'].isin((selected_full_path)), 1, 0 )\n",
    "\n",
    "df_phen = df_phen.loc[df_phen[\"SUB_IN_SMP\"] == 1]    \n",
    "df_phen = df_phen.loc[df_phen[\"selected\"] == 1]    \n",
    "\n",
    "df_phen.to_csv('./data/SelectedSubjects.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
